{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_447820/2081191832.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import  SparkContext\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/spark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/17 17:08:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/17 17:08:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/03/17 17:08:48 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"yarn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player_id  device_id event_date  games_played\n",
      "0          1          2 2016-03-01             5\n",
      "1          1          2 2016-03-02             6\n",
      "2          2          3 2017-06-25             1\n",
      "3          3          1 2016-03-01             0\n",
      "4          3          4 2016-07-03             5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'player_id': [1, 1, 2, 3, 3],\n",
    "    'device_id': [2, 2, 3, 1, 4],\n",
    "    'event_date': ['2016-03-01', '2016-03-02', '2017-06-25', '2016-03-01', '2016-07-03'],\n",
    "    'games_played': [5, 6, 1, 0, 5]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "activity_df = pd.DataFrame(data)\n",
    "\n",
    "# Convert event_date to datetime\n",
    "activity_df['event_date'] = pd.to_datetime(activity_df['event_date'])\n",
    "\n",
    "# Display the result\n",
    "print(activity_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_person = spark.createDataFrame(activity_df)\n",
    "df_person.createOrReplaceTempView(\"Activity\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select distinct event_date\n",
    "    from Activity\n",
    "    order by event_date asc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|         event_date|\n",
      "+-------------------+\n",
      "|2016-03-01 00:00:00|\n",
      "|2016-03-02 00:00:00|\n",
      "|2016-07-03 00:00:00|\n",
      "|2017-06-25 00:00:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "    select\n",
    "        *,\n",
    "        row_number() over (partition by player_id order by event_date asc) as order_login,\n",
    "        date_add(event_date, 1) = lead(event_date, 1, event_date) over (partition by player_id order by event_date asc) as day_one\n",
    "    from\n",
    "        Activity a \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+-----------+-------+\n",
      "|player_id|device_id|         event_date|games_played|order_login|day_one|\n",
      "+---------+---------+-------------------+------------+-----------+-------+\n",
      "|        1|        2|2016-03-01 00:00:00|           5|          1|   true|\n",
      "|        1|        2|2016-03-02 00:00:00|           6|          2|  false|\n",
      "|        2|        3|2017-06-25 00:00:00|           1|          1|  false|\n",
      "|        3|        1|2016-03-01 00:00:00|           0|          1|  false|\n",
      "|        3|        4|2016-07-03 00:00:00|           5|          2|  false|\n",
      "+---------+---------+-------------------+------------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+---------+---------+-------------------+------------+\n",
    "|player_id|device_id|         event_date|games_played|\n",
    "+---------+---------+-------------------+------------+\n",
    "|        1|        2|2016-03-01 00:00:00|           5|\n",
    "|        1|        2|2016-03-02 00:00:00|           6|\n",
    "|        2|        3|2017-06-25 00:00:00|           1|\n",
    "|        3|        1|2016-03-01 00:00:00|           0|\n",
    "|        3|        4|2016-07-03 00:00:00|           5|\n",
    "+---------+---------+-------------------+------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = f\"\"\"\n",
    "    select \n",
    "        *, \n",
    "        sum(if(day_one=true, 1, 0)) over(partition by event_date) / count(*) over(partition by event_date) as Day1_retention,\n",
    "        sum(if(day_one=true, 1, 0)) over(partition by event_date) as sum_day_one,\n",
    "        count(*) over(partition by event_date) as count_all\n",
    "    from ({query_1}) \n",
    "    where order_login = 1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+-----------+-------+--------------+-----------+---------+\n",
      "|player_id|device_id|         event_date|games_played|order_login|day_one|Day1_retention|sum_day_one|count_all|\n",
      "+---------+---------+-------------------+------------+-----------+-------+--------------+-----------+---------+\n",
      "|        1|        2|2016-03-01 00:00:00|           5|          1|  false|           0.0|          0|        2|\n",
      "|        3|        1|2016-03-01 00:00:00|           0|          1|  false|           0.0|          0|        2|\n",
      "|        2|        3|2017-06-25 00:00:00|           1|          1|  false|           0.0|          0|        1|\n",
      "+---------+---------+-------------------+------------+-----------+-------+--------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3 = f\"\"\"\n",
    "    with t as (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by player_id order by event_date asc) as order_login,\n",
    "            date_add(event_date, 1) = lead(event_date, 1, event_date) over (partition by player_id order by event_date asc) as day_one,\n",
    "            lead(event_date, 1, event_date) over (partition by player_id order by event_date asc) as abc\n",
    "        from\n",
    "            Activity a  \n",
    "    )\n",
    "\n",
    "    select \n",
    "        *\n",
    "    from t\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+-----------+-------+-------------------+\n",
      "|player_id|device_id|         event_date|games_played|order_login|day_one|                abc|\n",
      "+---------+---------+-------------------+------------+-----------+-------+-------------------+\n",
      "|        1|        2|2016-03-01 00:00:00|           5|          1|   true|2016-03-02 00:00:00|\n",
      "|        1|        2|2016-03-02 00:00:00|           6|          2|  false|2016-03-02 00:00:00|\n",
      "|        2|        3|2017-06-25 00:00:00|           1|          1|  false|2017-06-25 00:00:00|\n",
      "|        3|        1|2016-03-01 00:00:00|           0|          1|  false|2016-07-03 00:00:00|\n",
      "|        3|        4|2016-07-03 00:00:00|           5|          2|  false|2016-07-03 00:00:00|\n",
      "+---------+---------+-------------------+------------+-----------+-------+-------------------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#192, (cast(date_add(cast(event_date#2 as date), 1) as timestamp) = _we1#196) AS day_one#193, abc#194]\n",
      "   +- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#192, lead(event_date#2, 1, event_date#2) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS _we1#196, lead(event_date#2, 1, event_date#2) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS abc#194], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      "      +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(player_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=414]\n",
      "            +- Scan ExistingRDD[player_id#0L,device_id#1L,event_date#2,games_played#3L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_3).show()\n",
    "spark.sql(query_3).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3_1 = \"\"\"\n",
    "    with t as (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by player_id order by event_date asc) as order_login,\n",
    "            lead(event_date) over (partition by player_id order by event_date asc) as day_lead\n",
    "        from\n",
    "            Activity a  \n",
    "    )\n",
    "\n",
    "    select \n",
    "        *\n",
    "    from t\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+-----------+-------------------+\n",
      "|player_id|device_id|         event_date|games_played|order_login|           day_lead|\n",
      "+---------+---------+-------------------+------------+-----------+-------------------+\n",
      "|        1|        2|2016-03-01 00:00:00|           5|          1|2016-03-02 00:00:00|\n",
      "|        1|        2|2016-03-02 00:00:00|           6|          2|               NULL|\n",
      "|        2|        3|2017-06-25 00:00:00|           1|          1|               NULL|\n",
      "|        3|        1|2016-03-01 00:00:00|           0|          1|2016-07-03 00:00:00|\n",
      "|        3|        4|2016-07-03 00:00:00|           5|          2|               NULL|\n",
      "+---------+---------+-------------------+------------+-----------+-------------------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#1862, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#1863], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      "   +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(player_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=4307]\n",
      "         +- Scan ExistingRDD[player_id#0L,device_id#1L,event_date#2,games_played#3L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_3_1).show()\n",
    "spark.sql(query_3_1).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3_2 = \"\"\"\n",
    "\n",
    "    with t as (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by player_id order by event_date asc) as order_login,\n",
    "            lead(event_date) over (partition by player_id order by event_date asc) as day_lead\n",
    "        from\n",
    "            Activity a  \n",
    "    )\n",
    "\n",
    "    select \n",
    "        *\n",
    "    from t\n",
    "    where order_login = 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+-----------+--------+\n",
      "|player_id|device_id|event_date         |games_played|order_login|day_lead|\n",
      "+---------+---------+-------------------+------------+-----------+--------+\n",
      "|1        |2        |2016-03-01 00:00:00|5           |1          |NULL    |\n",
      "|2        |3        |2017-06-25 00:00:00|1           |1          |NULL    |\n",
      "|3        |1        |2016-03-01 00:00:00|0           |1          |NULL    |\n",
      "+---------+---------+-------------------+------------+-----------+--------+\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "CTE [t]\n",
      ":  +- 'SubqueryAlias t\n",
      ":     +- 'Project [*, 'row_number() windowspecdefinition('player_id, 'event_date ASC NULLS FIRST, unspecifiedframe$()) AS order_login#2035, 'lead('event_date) windowspecdefinition('player_id, 'event_date ASC NULLS FIRST, unspecifiedframe$()) AS day_lead#2036]\n",
      ":        +- 'SubqueryAlias a\n",
      ":           +- 'UnresolvedRelation [Activity], [], false\n",
      "+- 'Project [*]\n",
      "   +- 'Filter ('order_login = 1)\n",
      "      +- 'UnresolvedRelation [t], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "player_id: bigint, device_id: bigint, event_date: timestamp, games_played: bigint, order_login: int, day_lead: timestamp\n",
      "WithCTE\n",
      ":- CTERelationDef 58, false\n",
      ":  +- SubqueryAlias t\n",
      ":     +- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#2035, day_lead#2036]\n",
      ":        +- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#2035, day_lead#2036, order_login#2035, day_lead#2036]\n",
      ":           +- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#2035, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#2036], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      ":              +- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L]\n",
      ":                 +- SubqueryAlias a\n",
      ":                    +- SubqueryAlias activity\n",
      ":                       +- View (`Activity`, [player_id#0L,device_id#1L,event_date#2,games_played#3L])\n",
      ":                          +- LogicalRDD [player_id#0L, device_id#1L, event_date#2, games_played#3L], false\n",
      "+- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#2035, day_lead#2036]\n",
      "   +- Filter (order_login#2035 = 1)\n",
      "      +- SubqueryAlias t\n",
      "         +- CTERelationRef 58, true, [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#2035, day_lead#2036]\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (order_login#2035 = 1)\n",
      "+- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#2035, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#2036], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      "   +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1\n",
      "      +- LogicalRDD [player_id#0L, device_id#1L, event_date#2, games_played#3L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Filter (order_login#2035 = 1)\n",
      "   +- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#2035, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#2036], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      "      +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1, Final\n",
      "         +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\n",
      "            +- Exchange hashpartitioning(player_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=4761]\n",
      "               +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1, Partial\n",
      "                  +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\n",
      "                     +- Scan ExistingRDD[player_id#0L,device_id#1L,event_date#2,games_played#3L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_3_2).show(truncate=False)\n",
    "spark.sql(query_3_2).explain(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Parsed Logical Plan ==\n",
      "CTE [t]\n",
      ":  +- 'SubqueryAlias t\n",
      ":     +- 'Project [*, 'row_number() windowspecdefinition('player_id, 'event_date ASC NULLS FIRST, unspecifiedframe$()) AS order_login#1988, 'lead('event_date) windowspecdefinition('player_id, 'event_date ASC NULLS FIRST, unspecifiedframe$()) AS day_lead#1989]\n",
      ":        +- 'SubqueryAlias a\n",
      ":           +- 'UnresolvedRelation [Activity], [], false\n",
      "+- 'Project [*]\n",
      "   +- 'Filter ('order_login = 1)\n",
      "      +- 'UnresolvedRelation [t], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "player_id: bigint, device_id: bigint, event_date: timestamp, games_played: bigint, order_login: int, day_lead: timestamp\n",
      "WithCTE\n",
      ":- CTERelationDef 56, false\n",
      ":  +- SubqueryAlias t\n",
      ":     +- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#1988, day_lead#1989]\n",
      ":        +- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#1988, day_lead#1989, order_login#1988, day_lead#1989]\n",
      ":           +- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#1988, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#1989], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      ":              +- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L]\n",
      ":                 +- SubqueryAlias a\n",
      ":                    +- SubqueryAlias activity\n",
      ":                       +- View (`Activity`, [player_id#0L,device_id#1L,event_date#2,games_played#3L])\n",
      ":                          +- LogicalRDD [player_id#0L, device_id#1L, event_date#2, games_played#3L], false\n",
      "+- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#1988, day_lead#1989]\n",
      "   +- Filter (order_login#1988 = 1)\n",
      "      +- SubqueryAlias t\n",
      "         +- CTERelationRef 56, true, [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#1988, day_lead#1989]\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (order_login#1988 = 1)\n",
      "+- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#1988, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#1989], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      "   +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1\n",
      "      +- LogicalRDD [player_id#0L, device_id#1L, event_date#2, games_played#3L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Filter (order_login#1988 = 1)\n",
      "   +- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#1988, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#1989], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      "      +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1, Final\n",
      "         +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\n",
      "            +- Exchange hashpartitioning(player_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=4648]\n",
      "               +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1, Partial\n",
      "                  +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\n",
      "                     +- Scan ExistingRDD[player_id#0L,device_id#1L,event_date#2,games_played#3L]\n",
      "|\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "== Parsed Logical Plan ==\\nCTE [t]\\n:  +- 'SubqueryAlias t\\n:     +- 'Project [*, 'row_number() windowspecdefinition('player_id, 'event_date ASC NULLS FIRST, unspecifiedframe$()) AS order_login#1988, 'lead('event_date) windowspecdefinition('player_id, 'event_date ASC NULLS FIRST, unspecifiedframe$()) AS day_lead#1989]\\n:        +- 'SubqueryAlias a\\n:           +- 'UnresolvedRelation [Activity], [], false\\n+- 'Project [*]\\n   +- 'Filter ('order_login = 1)\\n      +- 'UnresolvedRelation [t], [], false\\n\\n== Analyzed Logical Plan ==\\nplayer_id: bigint, device_id: bigint, event_date: timestamp, games_played: bigint, order_login: int, day_lead: timestamp\\nWithCTE\\n:- CTERelationDef 56, false\\n:  +- SubqueryAlias t\\n:     +- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#1988, day_lead#1989]\\n:        +- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#1988, day_lead#1989, order_login#1988, day_lead#1989]\\n:           +- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#1988, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#1989], [player_id#0L], [event_date#2 ASC NULLS FIRST]\\n:              +- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L]\\n:                 +- SubqueryAlias a\\n:                    +- SubqueryAlias activity\\n:                       +- View (`Activity`, [player_id#0L,device_id#1L,event_date#2,games_played#3L])\\n:                          +- LogicalRDD [player_id#0L, device_id#1L, event_date#2, games_played#3L], false\\n+- Project [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#1988, day_lead#1989]\\n   +- Filter (order_login#1988 = 1)\\n      +- SubqueryAlias t\\n         +- CTERelationRef 56, true, [player_id#0L, device_id#1L, event_date#2, games_played#3L, order_login#1988, day_lead#1989]\\n\\n== Optimized Logical Plan ==\\nFilter (order_login#1988 = 1)\\n+- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#1988, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#1989], [player_id#0L], [event_date#2 ASC NULLS FIRST]\\n   +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1\\n      +- LogicalRDD [player_id#0L, device_id#1L, event_date#2, games_played#3L], false\\n\\n== Physical Plan ==\\nAdaptiveSparkPlan isFinalPlan=false\\n+- Filter (order_login#1988 = 1)\\n   +- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#1988, lead(event_date#2, 1, null) windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS day_lead#1989], [player_id#0L], [event_date#2 ASC NULLS FIRST]\\n      +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1, Final\\n         +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\\n            +- Exchange hashpartitioning(player_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=4648]\\n               +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1, Partial\\n                  +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\\n                     +- Scan ExistingRDD[player_id#0L,device_id#1L,event_date#2,games_played#3L]\\n|\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3_3 = \"\"\"\n",
    "    with t as (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by player_id order by event_date asc) as order_login\n",
    "        from\n",
    "            Activity a  \n",
    "    )\n",
    "\n",
    "    select \n",
    "        *\n",
    "    from t\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+-----------+\n",
      "|player_id|device_id|         event_date|games_played|order_login|\n",
      "+---------+---------+-------------------+------------+-----------+\n",
      "|        1|        2|2016-03-01 00:00:00|           5|          1|\n",
      "|        1|        2|2016-03-02 00:00:00|           6|          2|\n",
      "|        2|        3|2017-06-25 00:00:00|           1|          1|\n",
      "|        3|        1|2016-03-01 00:00:00|           0|          1|\n",
      "|        3|        4|2016-07-03 00:00:00|           5|          2|\n",
      "+---------+---------+-------------------+------------+-----------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#1735], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      "   +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(player_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=4067]\n",
      "         +- Scan ExistingRDD[player_id#0L,device_id#1L,event_date#2,games_played#3L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_3_3).show()\n",
    "spark.sql(query_3_3).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_4 = \"\"\"\n",
    "    select\n",
    "        *,\n",
    "        row_number() over (partition by player_id order by event_date asc) as order_login\n",
    "    from Activity a\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+-----------+\n",
      "|player_id|device_id|         event_date|games_played|order_login|\n",
      "+---------+---------+-------------------+------------+-----------+\n",
      "|        1|        2|2016-03-01 00:00:00|           5|          1|\n",
      "|        1|        2|2016-03-02 00:00:00|           6|          2|\n",
      "|        2|        3|2017-06-25 00:00:00|           1|          1|\n",
      "|        3|        1|2016-03-01 00:00:00|           0|          1|\n",
      "|        3|        4|2016-07-03 00:00:00|           5|          2|\n",
      "+---------+---------+-------------------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_5 = \"\"\"\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by player_id order by event_date asc) as order_login\n",
    "        from Activity a\n",
    "    ) where order_login = 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+-----------+\n",
      "|player_id|device_id|         event_date|games_played|order_login|\n",
      "+---------+---------+-------------------+------------+-----------+\n",
      "|        1|        2|2016-03-01 00:00:00|           5|          1|\n",
      "|        2|        3|2017-06-25 00:00:00|           1|          1|\n",
      "|        3|        1|2016-03-01 00:00:00|           0|          1|\n",
      "+---------+---------+-------------------+------------+-----------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Filter (order_login#1955 = 1)\n",
      "   +- Window [row_number() windowspecdefinition(player_id#0L, event_date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS order_login#1955], [player_id#0L], [event_date#2 ASC NULLS FIRST]\n",
      "      +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1, Final\n",
      "         +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\n",
      "            +- Exchange hashpartitioning(player_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=4552]\n",
      "               +- WindowGroupLimit [player_id#0L], [event_date#2 ASC NULLS FIRST], row_number(), 1, Partial\n",
      "                  +- Sort [player_id#0L ASC NULLS FIRST, event_date#2 ASC NULLS FIRST], false, 0\n",
      "                     +- Scan ExistingRDD[player_id#0L,device_id#1L,event_date#2,games_played#3L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_5).show()\n",
    "spark.sql(query_5).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_6 = \"\"\"\n",
    "WITH t AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        row_number() OVER (PARTITION BY player_id ORDER BY event_date ASC) AS order_login,\n",
    "        lead(event_date) OVER (PARTITION BY player_id ORDER BY event_date ASC) AS day_lead\n",
    "    FROM\n",
    "        Activity\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    player_id,\n",
    "    device_id,\n",
    "    event_date,\n",
    "    games_played,\n",
    "    CASE \n",
    "        WHEN order_login = 1 THEN LEAD(event_date) OVER (PARTITION BY player_id ORDER BY event_date ASC) \n",
    "        ELSE NULL \n",
    "    END AS day_lead\n",
    "FROM\n",
    "    t\n",
    "WHERE\n",
    "    order_login = 1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+--------+\n",
      "|player_id|device_id|         event_date|games_played|day_lead|\n",
      "+---------+---------+-------------------+------------+--------+\n",
      "|        1|        2|2016-03-01 00:00:00|           5|    NULL|\n",
      "|        2|        3|2017-06-25 00:00:00|           1|    NULL|\n",
      "|        3|        1|2016-03-01 00:00:00|           0|    NULL|\n",
      "+---------+---------+-------------------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_6).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
