{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_619698/2081191832.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import  SparkContext\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/spark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/16 10:27:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/16 10:28:01 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"yarn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friendship table:\n",
      "   user1_id  user2_id\n",
      "0         1         2\n",
      "1         1         3\n",
      "2         1         4\n",
      "3         2         3\n",
      "4         2         4\n",
      "5         2         5\n",
      "6         6         1\n",
      "\n",
      "Likes table:\n",
      "   user_id  page_id\n",
      "0        1       88\n",
      "1        2       23\n",
      "2        3       24\n",
      "3        4       56\n",
      "4        5       11\n",
      "5        6       33\n",
      "6        2       77\n",
      "7        3       77\n",
      "8        6       88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for the Friendship table\n",
    "friendship_data = {\n",
    "    'user1_id': [1, 1, 1, 2, 2, 2, 6],\n",
    "    'user2_id': [2, 3, 4, 3, 4, 5, 1]\n",
    "}\n",
    "\n",
    "# Sample data for the Likes table\n",
    "likes_data = {\n",
    "    'user_id': [1, 2, 3, 4, 5, 6, 2, 3, 6],\n",
    "    'page_id': [88, 23, 24, 56, 11, 33, 77, 77, 88]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrames\n",
    "friendship_df = pd.DataFrame(friendship_data)\n",
    "likes_df = pd.DataFrame(likes_data)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Friendship table:\")\n",
    "print(friendship_df)\n",
    "print(\"\\nLikes table:\")\n",
    "print(likes_df)\n",
    "\n",
    "\n",
    "df_person = spark.createDataFrame(friendship_df)\n",
    "df_person.createOrReplaceTempView(\"Friendship\")\n",
    "\n",
    "df_person = spark.createDataFrame(likes_df)\n",
    "df_person.createOrReplaceTempView(\"Likes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    with user as (\n",
    "        select\n",
    "            distinct\n",
    "            user_id,\n",
    "            friend_id\n",
    "        from (\n",
    "            select user1_id as user_id, user2_id as friend_id from Friendship\n",
    "            union all\n",
    "            select user2_id as user_id, user1_id as friend_id from Friendship\n",
    "        )\n",
    "        order by user_id\n",
    "    ),\n",
    "    \n",
    "    friend_like as (\n",
    "        select \n",
    "            u.user_id,\n",
    "            u.friend_id,\n",
    "            l1.page_id as friend_like_page\n",
    "        from user u \n",
    "            left join Likes l1 on u.friend_id = l1.user_id\n",
    "        order by user_id, friend_id\n",
    "    ),\n",
    "    \n",
    "    user_like as (\n",
    "        select \n",
    "            u.user_id,\n",
    "            l2.page_id as user_like_page\n",
    "        from user u \n",
    "            left join Likes l2 on u.user_id = l2.user_id\n",
    "        order by user_id\n",
    "    )\n",
    "    \n",
    "    select\n",
    "        user_id,\n",
    "        friend_like_page as page_id,\n",
    "        count(distinct friend_id) as friends_likes\n",
    "    from (\n",
    "        select \n",
    "            user_id,\n",
    "            friend_id,\n",
    "            friend_like_page\n",
    "        from friend_like f \n",
    "        where (f.user_id, f.friend_like_page) not in (\n",
    "            select user_id, user_like_page from user_like\n",
    "        )\n",
    "    )\n",
    "    group by user_id, friend_like_page\n",
    "    order by user_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------+\n",
      "|user_id|page_id|friends_likes|\n",
      "+-------+-------+-------------+\n",
      "|      1|     33|            1|\n",
      "|      1|     56|            1|\n",
      "|      1|     23|            1|\n",
      "|      1|     77|            2|\n",
      "|      1|     24|            1|\n",
      "|      2|     88|            1|\n",
      "|      2|     56|            1|\n",
      "|      2|     11|            1|\n",
      "|      2|     24|            1|\n",
      "|      3|     88|            1|\n",
      "|      3|     23|            1|\n",
      "|      4|     88|            1|\n",
      "|      4|     77|            1|\n",
      "|      4|     23|            1|\n",
      "|      5|     77|            1|\n",
      "|      5|     23|            1|\n",
      "+-------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
