{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3982/2081191832.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import  SparkContext\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/spark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/17 05:00:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/17 05:00:06 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"yarn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates table:\n",
      "   employee_id experience  salary\n",
      "0            1     Junior   10000\n",
      "1            9     Junior   10000\n",
      "2            2     Senior   20000\n",
      "3           11     Senior   20000\n",
      "4           13     Senior   50000\n",
      "5            4     Junior   40000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for the Candidates table\n",
    "candidates_data = {\n",
    "    'employee_id': [1, 9, 2, 11, 13, 4],\n",
    "    'experience': ['Junior', 'Junior', 'Senior', 'Senior', 'Senior', 'Junior'],\n",
    "    'salary': [10000, 10000, 20000, 20000, 50000, 40000]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "candidates_df = pd.DataFrame(candidates_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Candidates table:\")\n",
    "print(candidates_df)\n",
    "\n",
    "data = {\n",
    "    'employee_id': [1, 9, 2, 11, 13, 4],\n",
    "    'experience': ['Junior', 'Junior', 'Senior', 'Senior', 'Senior', 'Junior'],\n",
    "    'salary': [10000, 10000, 80000, 80000, 80000, 40000]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "df_person = spark.createDataFrame(candidates_df)\n",
    "df_person.createOrReplaceTempView(\"Candidates\")\n",
    "\n",
    "df_person = spark.createDataFrame(df)\n",
    "df_person.createOrReplaceTempView(\"Candidates_1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    with senior_salary as (\n",
    "        select\n",
    "            *,\n",
    "            sum(salary) over(order by rk asc) as total_salary\n",
    "        from (\n",
    "            select\n",
    "                *,\n",
    "                row_number() over(order by salary asc) as rk\n",
    "            from Candidates_1 c \n",
    "            where experience = 'Senior'\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    junior_salary as (\n",
    "        select\n",
    "            *,\n",
    "            sum(salary) over(order by rk asc) as total_salary\n",
    "        from (\n",
    "            select\n",
    "                *,\n",
    "                row_number() over(order by salary asc) as rk\n",
    "            from Candidates_1 c \n",
    "            where experience = 'Junior'\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    senior_get as (\n",
    "        select\n",
    "            *\n",
    "        from senior_salary \n",
    "        where total_salary <= 70000\n",
    "    )\n",
    "    \n",
    "    select \n",
    "        'Junior' as experience,\n",
    "        count(*) as accepted_candidates\n",
    "    from junior_salary \n",
    "    where total_salary <= (70000 - ifnull((select max(total_salary) from senior_get), 0))\n",
    "    union all\n",
    "    select\n",
    "        'Senior' as experience,\n",
    "        count(*) as accepted_candidates\n",
    "    from senior_get\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/17 06:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|experience|accepted_candidates|\n",
      "+----------+-------------------+\n",
      "|    Junior|                  3|\n",
      "|    Senior|                  0|\n",
      "+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "    select\n",
    "        *\n",
    "    from Candidates c \n",
    "    where experience = 'Senior'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+\n",
      "|employee_id|experience|salary|\n",
      "+-----------+----------+------+\n",
      "|          2|    Senior| 20000|\n",
      "|         11|    Senior| 20000|\n",
      "|         13|    Senior| 50000|\n",
      "+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query_1).createOrReplaceTempView(\"SeniorSalary\")\n",
    "spark.sql(query_1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
