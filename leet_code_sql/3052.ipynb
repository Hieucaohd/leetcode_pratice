{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2179/2081191832.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import  SparkContext\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/spark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/21 11:52:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/21 11:52:27 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"yarn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory table:\n",
      "   item_id       item_type item_category  square_footage\n",
      "0     1374  prime_eligible       Watches            68.0\n",
      "1     4245       not_prime           Art            26.4\n",
      "2     5743  prime_eligible      Software           325.0\n",
      "3     8543       not_prime      Clothing            64.5\n",
      "4     2556       not_prime         Shoes            15.0\n",
      "5     2452  prime_eligible    Scientific            85.0\n",
      "6     3255       not_prime     Furniture            22.6\n",
      "7     1672  prime_eligible        Beauty             8.5\n",
      "8     4256  prime_eligible     Furniture            55.5\n",
      "9     6325  prime_eligible          Food            13.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for Inventory table\n",
    "inventory_data = {\n",
    "    'item_id': [1374, 4245, 5743, 8543, 2556, 2452, 3255, 1672, 4256, 6325],\n",
    "    'item_type': ['prime_eligible', 'not_prime', 'prime_eligible', 'not_prime', 'not_prime', 'prime_eligible', 'not_prime', 'prime_eligible', 'prime_eligible', 'prime_eligible'],\n",
    "    'item_category': ['Watches', 'Art', 'Software', 'Clothing', 'Shoes', 'Scientific', 'Furniture', 'Beauty', 'Furniture', 'Food'],\n",
    "    'square_footage': [68.00, 26.40, 325.00, 64.50, 15.00, 85.00, 22.60, 8.50, 55.50, 13.20]\n",
    "}\n",
    "\n",
    "# Create DataFrame for Inventory\n",
    "inventory_df = pd.DataFrame(inventory_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Inventory table:\")\n",
    "print(inventory_df)\n",
    "\n",
    "\n",
    "\n",
    "df_person = spark.createDataFrame(inventory_df)\n",
    "df_person.createOrReplaceTempView(\"Inventory\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    with t as (\n",
    "        select\n",
    "            item_type,\n",
    "            sum(square_footage) as total_square,\n",
    "            count(*) as total_item\n",
    "        from Inventory i \n",
    "        group by item_type\n",
    "    ),\n",
    "    \n",
    "    remain_square as (\n",
    "        select\n",
    "            *,\n",
    "            500000 - max_item * total_square as remain_square\n",
    "        from (\n",
    "            select\n",
    "                item_type,\n",
    "                total_square,\n",
    "                total_item,\n",
    "                cast(500000 / total_square as int) as max_item\n",
    "            from t\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    select \n",
    "        'not_prime' as item_type, \n",
    "        cast(\n",
    "            (select remain_square from remain_square where item_type = 'prime_eligible' limit 1) \n",
    "            / \n",
    "            (select total_square from t where item_type = 'not_prime' limit 1) as int    \n",
    "        ) * (select total_item from t where item_type = 'not_prime' limit 1) as item_count\n",
    "    union all\n",
    "    select\n",
    "        'prime_eligible' as item_type,\n",
    "        cast(\n",
    "            500000 \n",
    "            / \n",
    "            (select total_square from t where item_type = 'prime_eligible' limit 1) as int\n",
    "        ) * (select total_item from t where item_type = 'prime_eligible' limit 1) as item_count\n",
    "    \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|     item_type|item_count|\n",
      "+--------------+----------+\n",
      "|     not_prime|         8|\n",
      "|prime_eligible|      5400|\n",
      "+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
